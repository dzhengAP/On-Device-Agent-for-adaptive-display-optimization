The system achieves 92% accuracy with CoreML acceleration delivering 21.3 tokens/second on M3 Pro (7.89Ã— speedup), enabling sub-second responses. Our LoRA fine-tuned TinyLlama 1.1B proves hybrid approaches superior for responsive, context-aware optimization without cloud dependencies. The pdf paper can be found in this link![PDF](https://i0.wp.com/dqzheng.com/wp-content/uploads/2025/09/System-2.png?w=1280&ssl=1)
![Alt text](https://i0.wp.com/dqzheng.com/wp-content/uploads/2025/09/System-2.png?w=1280&ssl=1)
